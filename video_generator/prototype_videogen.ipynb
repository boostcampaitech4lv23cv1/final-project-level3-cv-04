{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "from glob import glob\n",
    "import cv2\n",
    "import csv\n",
    "import pandas as pd\n",
    "import natsort\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "import json\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter   \n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/final-project-level3-cv-04/result/0lXwMdnpoFQ/20/csv/pred.pickle', mode='rb') as f:\n",
    "    pred = pickle.load(f)\n",
    "\n",
    "with open('/opt/ml/final-project-level3-cv-04/result/0lXwMdnpoFQ/20/csv/df1_face.pickle', mode='rb') as f:\n",
    "    df1 = pickle.load(f)\n",
    "\n",
    "with open('/opt/ml/final-project-level3-cv-04/result/0lXwMdnpoFQ/20/0lXwMdnpoFQ.json', mode='r') as f:\n",
    "    meta_info = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### clansing\n",
    "def clansing(df:pd.DataFrame, pred:dict) -> pd.DataFrame:\n",
    "    # drop useless column\n",
    "    df.drop(['det_body_xmin', \n",
    "             'det_body_ymin', \n",
    "             'det_body_xmax',\n",
    "             'det_body_ymax',\n",
    "             'det_conf',\n",
    "             'track_body_xmin',\n",
    "             'track_body_ymin',\n",
    "             'track_body_xmax',\n",
    "             'track_body_ymax',\n",
    "             'track_conf',\n",
    "             'num_overlap_bboxes',\n",
    "             'intercept_iou',\n",
    "             'isfront',\n",
    "             'face_bbox',\n",
    "             'face_embedding',\n",
    "             'face_confidence'], axis=1, inplace=True)\n",
    "    # track_id type change\n",
    "    df['track_id'] = df['track_id'].astype('int32')\n",
    "\n",
    "    # assign name\n",
    "    for k,v in pred.items():\n",
    "        df.loc[df['track_id']==k,'name'] = v\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "#### get face order\n",
    "def get_order(element, lst):\n",
    "    try:\n",
    "        return lst.index(element)\n",
    "    except ValueError:\n",
    "        return -1\n",
    "\n",
    "\n",
    "#### for key point assign\n",
    "def get_keypoint(element, idx):\n",
    "    if idx != -1:\n",
    "        left_eye_point = element[idx][0]\n",
    "        right_eye_point = element[idx][1]\n",
    "        center_point = [int((x + y)/2) for x, y in zip(left_eye_point, right_eye_point)]\n",
    "        return center_point\n",
    "    else: # if un detected keypoints return [-1,-1]\n",
    "        return [-1, -1]\n",
    "\n",
    "\n",
    "#### add bbox column\n",
    "def keypoint_center_bounding_box(coord, crop_width, crop_height):\n",
    "    x, y = coord\n",
    "    if x==-1 or y==-1: # if undetected keypoints [-1,-1]\n",
    "        return [-1,-1,-1,-1]\n",
    "    x_min = x - crop_width / 2\n",
    "    y_min = y - crop_height / 2\n",
    "    x_max = x + crop_width / 2\n",
    "    y_max = y + crop_height / 2\n",
    "    coordinate = [int(i) for i in [x_min, y_min, x_max, y_max]] # int coordinate\n",
    "    return coordinate\n",
    "\n",
    "\n",
    "#### add shift bbox column\n",
    "def shift_bounding_box(bbox, shift_ratio, meta_info):\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "    if x_min == -1 or y_min == -1 or x_max == -1 or y_max == -1:\n",
    "        return [0,0,meta_info['width'],meta_info['height']]\n",
    "    height = y_max - y_min\n",
    "    y_min += height * shift_ratio\n",
    "    y_max += height * shift_ratio\n",
    "    coordinate = [int(i) for i in [x_min, y_min, x_max, y_max]]\n",
    "    return coordinate\n",
    "\n",
    "\n",
    "#### add missing rows\n",
    "def add_missing_files(df, all_files, name, meta_info):\n",
    "    missing_files = set(all_files) - set(df['filename'])\n",
    "    if missing_files:\n",
    "        missing_df = pd.DataFrame({\n",
    "                                    'frame':[int(filename.split('.')[0]) for filename in list(missing_files)],\n",
    "                                    'filename': list(missing_files), \n",
    "                                    'name': [name for i in list(missing_files)],\n",
    "                                    'shift_bbox': [[0,0,meta_info['width'],meta_info['height']] for i in list(missing_files)],\n",
    "                                    })\n",
    "        df = df.append(missing_df, ignore_index=True)\n",
    "    df = df.sort_values(by='frame' ,ascending=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "#### Define a function to collect the values of columns A, B, C, and D as a list\n",
    "def collect_values(row):\n",
    "    return [row['xmin'], row['ymin'], row['xmax'], row['ymax']]\n",
    "\n",
    "\n",
    "#### tagging untrack frame\n",
    "def tagging_untrack_frame(row, meta_info):\n",
    "    if row == [0, 0, meta_info['width'], meta_info['height']]:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "#### smoothing\n",
    "def smoothing(df, target_column):\n",
    "    # split coordinates\n",
    "    df['xmin'] = [coordinate[0] for coordinate in df[target_column]]\n",
    "    df['ymin'] = [coordinate[1] for coordinate in df[target_column]]\n",
    "    df['xmax'] = [coordinate[2] for coordinate in df[target_column]]\n",
    "    df['ymax'] = [coordinate[3] for coordinate in df[target_column]]\n",
    "    \n",
    "    df['xmin'] = df[['xmin']].apply(savgol_filter,  window_length=45, polyorder=2)\n",
    "    df['ymin'] = df[['ymin']].apply(savgol_filter,  window_length=45, polyorder=2)\n",
    "    df['xmax'] = df[['xmax']].apply(savgol_filter,  window_length=45, polyorder=2)\n",
    "    df['ymax'] = df[['ymax']].apply(savgol_filter,  window_length=45, polyorder=2)\n",
    "\n",
    "    df['xmin'] = df['xmin'].astype('int')\n",
    "    df['ymin'] = df['ymin'].astype('int')\n",
    "    df['xmax'] = df['xmax'].astype('int')\n",
    "    df['ymax'] = df['ymax'].astype('int')\n",
    "\n",
    "    df['smoothed_bbox'] = df.apply(collect_values, axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def trim(df):\n",
    "    # drop useless column\n",
    "    df.drop(['face_keypoint', \n",
    "             'face_pred', \n",
    "             'key_point_order',\n",
    "             'center_point',\n",
    "            #  'xmin',\n",
    "            #  'ymin',\n",
    "            #  'xmax',\n",
    "            #  'ymax'\n",
    "            ], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# top, bottom, left, right ; 경계의 각 방향에 대한 선의 폭\n",
    "def img_padding(img, xmin, ymin, xmax, ymax, w, h):   # img 사이즈 범위 밖으로 벗어나면 그에맞게 padding\n",
    "    # xmin, ymin, xmax, ymax\n",
    "    if xmax>w:\n",
    "        img = cv2.copyMakeBorder(img, 0, 0, 0, xmax-w, cv2.BORDER_CONSTANT) # right xmax-w add pixel\n",
    "    \n",
    "    if xmin<0: # xmin is minus\n",
    "        img = cv2.copyMakeBorder(img, 0, 0,-xmin, 0, cv2.BORDER_CONSTANT) # left -xmin add pixel\n",
    "        xmax = xmax - xmin # 1024-(-125)\n",
    "        xmin = 0\n",
    "    \n",
    "    if ymax>h:\n",
    "        img = cv2.copyMakeBorder(img, 0, ymax-h, 0, 0, cv2.BORDER_CONSTANT) # bottom ymax-h add pixel\n",
    "    \n",
    "    if ymin<0:\n",
    "        img = cv2.copyMakeBorder(img, -ymin, 0, 0, 0, cv2.BORDER_CONSTANT) # bottom ymax-h add pixel\n",
    "        py = ymax - ymin\n",
    "        ymin = 0\n",
    "    \n",
    "    return img, xmin, ymin, xmax, ymax\n",
    "\n",
    "\n",
    "def change_short_time_undetect_bbox(df, fps):\n",
    "    values = np.array(df['is_track'].tolist())\n",
    "    run_sum = np.cumsum(values)\n",
    "    for n in set(run_sum):\n",
    "        indices = np.where(run_sum == n)\n",
    "        indices = indices[0].tolist()\n",
    "        if len(indices) <= fps:\n",
    "\n",
    "            start_bbox_coord = df.iloc[indices[0]]['smoothed_bbox']\n",
    "\n",
    "            for idx in indices:\n",
    "                df.at[idx,'smoothed_bbox'] = start_bbox_coord\n",
    "    return df\n",
    "\n",
    "def moving_avg_untrackrow(df, keep_threshold):\n",
    "    df['increase_decrease_bbox'] = [None] * len(df)\n",
    "    df.at[0, 'increase_decrease_bbox'] = df.at[0, 'shift_bbox']\n",
    "\n",
    "    cnt=0\n",
    "    last_state=None\n",
    "    df['is_track_update'] = [False]*len(df)\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        # if untrack case\n",
    "        if df.at[i, 'shift_bbox'] == [0,0,2880,2160] and df.at[i, 'is_track'] == False:\n",
    "            # increase cnt\n",
    "            cnt+=1\n",
    "            if i > 0 and i < len(df) - 1:\n",
    "                # calculate the average of the previous and next values for each component of shift_bbox\n",
    "                xmin = int((df.at[i-1, 'shift_bbox'][0] + df.at[i+1, 'shift_bbox'][0]) / 2)\n",
    "                ymin = int((df.at[i-1, 'shift_bbox'][1] + df.at[i+1, 'shift_bbox'][1]) / 2)\n",
    "                xmax = int((df.at[i-1, 'shift_bbox'][2] + df.at[i+1, 'shift_bbox'][2]) / 2)\n",
    "                ymax = int((df.at[i-1, 'shift_bbox'][3] + df.at[i+1, 'shift_bbox'][3]) / 2)\n",
    "                # update the values of shift_bbox in the current row\n",
    "                df.at[i, 'increase_decrease_bbox'] = [xmin, ymin, xmax, ymax]\n",
    "                # update state\n",
    "            elif i == 0:\n",
    "                # if the current row is the first row, take the value of the next row\n",
    "                df.at[i, 'increase_decrease_bbox'] = df.at[i+1, 'shift_bbox']\n",
    "            else:\n",
    "                # if the current row is the last row, take the value of the previous row\n",
    "                df.at[i, 'increase_decrease_bbox'] = df.at[i-1, 'shift_bbox']\n",
    "            # df.at[i, 'is_track_update'] = True\n",
    "        \n",
    "        # if tracked appeared\n",
    "        else:\n",
    "            # if under_threshold replace last state\n",
    "            # df.at[i, 'is_track_update'] = False\n",
    "            \n",
    "            # update short track_state\n",
    "            if 0<cnt<keep_threshold:\n",
    "                for j in range(cnt):\n",
    "                    target_idx = i-(j+1)\n",
    "                    df.at[target_idx, 'increase_decrease_bbox'] = last_state\n",
    "                    df.at[target_idx, 'is_track_update'] = True # if short time state update\n",
    "            \n",
    "            cnt=0\n",
    "            df.at[i, 'increase_decrease_bbox'] = df.at[i, 'shift_bbox']\n",
    "            last_state=df.at[i, 'shift_bbox']\n",
    "    df['need_padding'] = df['is_track'] | df['is_track_update']\n",
    "    return df\n",
    "\n",
    "\n",
    "def crop_resize_save_img(df, img_dir_path, save_dir, name, meta_info, target_col, window_height, window_width, mode):\n",
    "\n",
    "    mini_df = df[['filename', target_col, 'need_padding']]\n",
    "    cnt=0\n",
    "    width = meta_info['width']\n",
    "    height = meta_info['height']\n",
    "    padded_box = []\n",
    "\n",
    "    # mini_df['need_padding'] = mini_df['is_track'] | mini_df['is_track_update']\n",
    "\n",
    "    # make dir\n",
    "    dir_path = osp.join(save_dir, name)\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "    print(f\"start cropping {len(df)} images.\")\n",
    "    for order, (index, row) in tqdm(enumerate(mini_df.iterrows())):\n",
    "        # load\n",
    "        img = cv2.imread(osp.join(img_dir_path, row['filename']))\n",
    "        # get bbox coordinate\n",
    "        xmin, ymin, xmax, ymax = row[target_col][0], row[target_col][1], row[target_col][2], row[target_col][3]\n",
    "        if row['need_padding']: # tracked\n",
    "            # get center-point\n",
    "            center_y, center_x = (ymin+ymax)//2, (xmin+xmax)//2\n",
    "            # get new xmin, ymin, xmax, ymax\n",
    "            xmin, ymin, xmax, ymax = center_x-window_width//2, center_y-window_height//2, center_x+window_width//2, center_y+window_height//2\n",
    "            # if over range, padding around\n",
    "            if xmax>width or xmin<0 or ymax>height or ymin<0:\n",
    "                img, xmin, ymin, xmax, ymax = img_padding(img, xmin, ymin, xmax, ymax, width, height)\n",
    "            # crop\n",
    "            img = img[ymin:ymax, xmin:xmax]\n",
    "        else: # untracked\n",
    "            if mode == 'normal': \n",
    "                img = cv2.resize(img, dsize=(window_width, window_height), interpolation=cv2.INTER_CUBIC)\n",
    "        # append\n",
    "        padded_box.append([xmin, ymin, xmax, ymax])\n",
    "        # if unmatching window img print size\n",
    "        if img.shape[0] != window_height and img.shape[1] != window_width:\n",
    "            # print(img.shape[0], window_height, img.shape[1], window_width)\n",
    "            pass\n",
    "        # write img\n",
    "        cv2.imwrite(osp.join(dir_path, row['filename']), img)\n",
    "    df['cropped_box'] = padded_box\n",
    "    return df, dir_path\n",
    "\n",
    "def enlarge_with_padding(img, crop_width, crop_height, window_width, window_height, padding_tag):\n",
    "    if padding_tag == True:\n",
    "        padded_img = np.zeros((window_height, window_width, 3), dtype=np.uint8)\n",
    "        x_offset = int((window_width - crop_width) / 2)\n",
    "        y_offset = int((window_height - crop_height) / 2)\n",
    "        padded_img[y_offset:y_offset+crop_height, x_offset:x_offset+crop_width, :] = img\n",
    "    else:\n",
    "        padded_img = cv2.resize(img, (window_width, window_height), interpolation=cv2.INTER_CUBIC)\n",
    "    # print(padding_tag, padded_img.shape)\n",
    "    return padded_img\n",
    "\n",
    "# make_video(crop_img_path, df, meta_info, save_dir, window_height, window_width, member)\n",
    "def make_video(dir_path, df, meta_info, save_dir, window_height, window_width, name):\n",
    "    files = os.listdir(dir_path)\n",
    "    padding_tags = df['need_padding'].to_list()\n",
    "    img_list = natsort.natsorted(files)\n",
    "    img_paths = [osp.join(dir_path, i) for i in img_list]\n",
    "    video_path = osp.join(save_dir, f'{name}_output.mp4')\n",
    "    out = cv2.VideoWriter(video_path,\n",
    "                          cv2.VideoWriter_fourcc(*'mp4v'), \n",
    "                          meta_info['fps'], \n",
    "                          (window_width, window_height))\n",
    "    img = cv2.imread(img_paths[0])\n",
    "    crop_h,crop_w,c = img.shape\n",
    "\n",
    "    tag = 'normal'\n",
    "    if window_height == crop_h and window_width == crop_w:\n",
    "        tag = 'normal'\n",
    "    elif window_height == crop_h and window_width != crop_w:\n",
    "        tag = 'vertical'\n",
    "    elif window_height != crop_h and window_width == crop_w:\n",
    "        tag = 'horizontal'\n",
    "    else:\n",
    "        raise ValueError(\"view type error\")\n",
    "\n",
    "    print(f\"{name}'s video recoding...\")\n",
    "    for path, padding_tag in tqdm(zip(img_paths, padding_tags)):\n",
    "        img = cv2.imread(path)\n",
    "        # enlarge_with_padding(img, crop_width, crop_height, window_width, window_height)\n",
    "        if tag == 'vertical' or tag=='horizontal':\n",
    "            # def enlarge_with_padding(img, crop_width, crop_height, window_width, window_height, padding_tag):\n",
    "            img = enlarge_with_padding(img, crop_w, crop_h,window_width, window_height, padding_tag)\n",
    "        # if normal don't need post processing\n",
    "        out.write(img)\n",
    "    out.release()\n",
    "    h,w,c = img.shape\n",
    "    \n",
    "    return video_path\n",
    "\n",
    "\n",
    "\n",
    "def video_gen(df:pd.DataFrame, meta_info:dict, member:str, pred:dict,  save_dir:str,\n",
    "             window_ratio:float, aespect_ratio:float, shift_bb:float):\n",
    "\n",
    "    view_type = None\n",
    "    \n",
    "    # calc window size\n",
    "    window_height = int(meta_info['height']*window_ratio)\n",
    "    window_width = int(meta_info['width']*window_ratio)\n",
    "\n",
    "    print(f'window size: hegiht:{window_height}, width:{window_width}')\n",
    "\n",
    "    if aespect_ratio >= 1:\n",
    "        print('horizontal mode') # width fix\n",
    "        mode = 'horizontal'\n",
    "        crop_width = window_width # width is Criteria\n",
    "        crop_height = int(crop_width * 1/aespect_ratio)\n",
    "    elif aespect_ratio==0:\n",
    "        print('normal mode')\n",
    "        mode = 'normal'\n",
    "        crop_height = window_height\n",
    "        crop_width = window_width\n",
    "    else:\n",
    "        print('vertical mode')\n",
    "        mode = 'vertical'\n",
    "        crop_height = window_height\n",
    "        crop_width = int(crop_height*aespect_ratio)\n",
    "\n",
    "    # 1. clansing df\n",
    "    df = clansing(df, pred)\n",
    "    \n",
    "    # 2. assign key_point order\n",
    "    df['key_point_order'] = df.apply(lambda x: get_order(x['name'], x['face_pred']), axis=1)\n",
    "\n",
    "    # 3. get center point(int type)\n",
    "    df1['center_point'] = df1.apply(lambda x: get_keypoint(x['face_keypoint'], x['key_point_order']), axis=1)\n",
    "\n",
    "    # 4. get center_bbox(bbox center is key_point)\n",
    "    df['center_bbox'] = df['center_point'].apply(lambda x: keypoint_center_bounding_box(x, crop_height, crop_width))\n",
    "\n",
    "    # 5. shifting bbox, if undetected keypoints or unmatching preds bbox is full\n",
    "    df['shift_bbox'] = df['center_bbox'].apply(lambda x: shift_bounding_box(x, shift_bb, meta_info))\n",
    "\n",
    "    # 6. extract selected member\n",
    "    df = df[df['name'] == member]\n",
    "\n",
    "    # 7. get all captures img filenames\n",
    "    img_dir_path = meta_info['image_root'].replace('.','..') # change for current path\n",
    "    img_files = os.listdir(img_dir_path)\n",
    "\n",
    "    # 8. add missing rows\n",
    "    df = add_missing_files(df, img_files, member, meta_info)\n",
    "\n",
    "    # 9. tagging untracked frame\n",
    "    df['is_track'] = df['shift_bbox'].apply(lambda x: tagging_untrack_frame(x, meta_info))\n",
    "    \n",
    "    # 10. trim, drop useless column\n",
    "    df = trim(df)\n",
    "\n",
    "    # 11. moving avg untrack row\n",
    "    df = moving_avg_untrackrow(df, keep_threshold=meta_info['fps']) # df add column increase_decrease_bbox\n",
    "\n",
    "    # option. smoothing\n",
    "    df = smoothing(df, 'increase_decrease_bbox') # df add column smoothed_bbox\n",
    "\n",
    "    # 12. clip img for over bbox, if long untracked frame made by resume\n",
    "    df, crop_img_path = crop_resize_save_img(df, \n",
    "                                             img_dir_path, \n",
    "                                             save_dir, \n",
    "                                             member, \n",
    "                                             meta_info, \n",
    "                                             'smoothed_bbox', \n",
    "                                             crop_height, \n",
    "                                             crop_width, \n",
    "                                             mode)\n",
    "    \n",
    "    # 13. making video\n",
    "    make_video(crop_img_path, df, meta_info, save_dir, window_height, window_width, member)\n",
    "    \n",
    "    # 14. delete crop imgs\n",
    "    shutil.rmtree(crop_img_path)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window size: hegiht:1080, width:1440\n",
      "normal mode\n",
      "start cropping 480 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "480it [00:39, 12.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aespa_ningning's video recoding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "480it [00:15, 30.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# vertical\n",
    "# video_gen(df1,  meta_info, 'aespa_ningning', pred, './', window_ratio=0.5, aespect_ratio=0.5, shift_bb=0.8).to_csv('result.csv') # asepect_ratio = width/height\n",
    "\n",
    "# normal\n",
    "video_gen(df1,  meta_info, 'aespa_ningning', pred, './', window_ratio=0.5, aespect_ratio=0., shift_bb=0.2).to_csv('result.csv') # asepect_ratio = width/height\n",
    "\n",
    "# horizontal\n",
    "# video_gen(df1,  meta_info, 'aespa_ningning', pred, './', window_ratio=0.5, aespect_ratio=2, shift_bb=0.1).to_csv('result.csv') # asepect_ratio = width/height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create the sample data frame\n",
    "df = pd.DataFrame({'shift_bbox': [[0,0,2880,2160], #1\n",
    "                                  [100,200,300,400], #2\n",
    "                                  [200,100,400,300], #3\n",
    "                                  [0,0,2880,2160], #4\n",
    "                                  [0,0,2880,2160], #5\n",
    "                                  [0,0,2880,2160], #6\n",
    "                                  [200,100,400,300], #7\n",
    "                                  [0,0,2880,2160], #8\n",
    "                                  [0,0,2880,2160], #9\n",
    "                                  [100,200,300,400], #10\n",
    "                                  [200,100,400,300], #11\n",
    "                                  [0,0,2880,2160], #12\n",
    "                                  [0,0,2880,2160], #13\n",
    "                                  [100,200,300,400], #14\n",
    "                                  [0,0,2880,2160]], #15\n",
    "                    'is_track': [False, #1\n",
    "                                 True, #2\n",
    "                                 True, #3\n",
    "                                 False, #4\n",
    "                                 False, #5\n",
    "                                 False, #6\n",
    "                                 True, #7\n",
    "                                 False, #8\n",
    "                                 False, #9\n",
    "                                 True, #10\n",
    "                                 True, #11\n",
    "                                 False, #12\n",
    "                                 False, #13\n",
    "                                 True, #14\n",
    "                                 False]}) #15 \n",
    "\n",
    "print(df)\n",
    "print('='*50)\n",
    "df['increase_decrease_bbox'] = [None] * len(df)\n",
    "df.at[0, 'increase_decrease_bbox'] = df.at[0, 'shift_bbox']\n",
    "# iterate through each row in the data frame\n",
    "cnt = 0\n",
    "threshold = 3\n",
    "last_state = None\n",
    "for i in range(1, len(df)):\n",
    "    # if the conditions are met\n",
    "    if df.at[i, 'shift_bbox'] == [0,0,2880,2160] and df.at[i, 'is_track'] == False:\n",
    "        # increase cnt\n",
    "        cnt+=1\n",
    "\n",
    "        if i > 0 and i < len(df) - 1:\n",
    "            # calculate the average of the previous and next values for each component of shift_bbox\n",
    "            xmin = (df.at[i-1, 'shift_bbox'][0] + df.at[i+1, 'shift_bbox'][0]) / 2\n",
    "            ymin = (df.at[i-1, 'shift_bbox'][1] + df.at[i+1, 'shift_bbox'][1]) / 2\n",
    "            xmax = (df.at[i-1, 'shift_bbox'][2] + df.at[i+1, 'shift_bbox'][2]) / 2\n",
    "            ymax = (df.at[i-1, 'shift_bbox'][3] + df.at[i+1, 'shift_bbox'][3]) / 2\n",
    "            # update the values of shift_bbox in the current row\n",
    "            df.at[i, 'increase_decrease_bbox'] = [xmin, ymin, xmax, ymax]\n",
    "        elif i == 0:\n",
    "            # if the current row is the first row, take the value of the next row\n",
    "            df.at[i, 'increase_decrease_bbox'] = df.at[i+1, 'shift_bbox']\n",
    "        else:\n",
    "            # if the current row is the last row, take the value of the previous row\n",
    "            df.at[i, 'increase_decrease_bbox'] = df.at[i-1, 'shift_bbox']\n",
    "    \n",
    "    else:\n",
    "        if 0<cnt<threshold: # if threshold under\n",
    "            print(i, cnt, df.at[i, 'shift_bbox'])\n",
    "            for j in range(cnt):\n",
    "                target_idx = i-(j+1)\n",
    "                # print('target_idx', target_idx, last_state)\n",
    "                df.at[target_idx, 'increase_decrease_bbox'] = last_state\n",
    "\n",
    "        # reset cnt\n",
    "        cnt=0\n",
    "        df.at[i, 'increase_decrease_bbox'] = df.at[i, 'shift_bbox']\n",
    "        last_state = df.at[i, 'shift_bbox']\n",
    "        \n",
    "\n",
    "# display the updated data frame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter    \n",
    "\n",
    "# noisy data\n",
    "x = [6903.79, 6838.04, 6868.57, 6621.25, 7101.99, 7026.78, 7248.6, 7121.4, 6828.98, 6841.36, 7125.12, 7483.96, 7505.0, 7539.03, 7693.1, 7773.51, 7738.58, 8778.58, 8620.0, 8825.67, 8972.58, 8894.15, 8871.92, 9021.36, 9143.4, 9986.3, 9800.02, 9539.1, 8722.77, 8562.04, 8810.99, 9309.35, 9791.97, 9315.96, 9380.81, 9681.11, 9733.93, 9775.13, 9511.43, 9067.51, 9170.0, 9179.01, 8718.14, 8900.35, 8841.0, 9204.07, 9575.87, 9426.6, 9697.72, 9448.27, 10202.71, 9518.02, 9666.32, 9788.14, 9621.17, 9666.85, 9746.99, 9782.0, 9772.44, 9885.22, 9278.88, 9464.96, 9473.34, 9342.1, 9426.05, 9526.97, 9465.13, 9386.32, 9310.23, 9358.95, 9294.69, 9685.69, 9624.33, 9298.33, 9249.49, 9162.21, 9012.0, 9116.16, 9192.93, 9138.08, 9231.99, 9086.54, 9057.79, 9135.0, 9069.41, 9342.47, 9257.4, 9436.06, 9232.42, 9288.34, 9234.02, 9303.31, 9242.61, 9255.85, 9197.6, 9133.72, 9154.31, 9170.3, 9208.99, 9160.78, 9390.0, 9518.16, 9603.27, 9538.1, 9700.42, 9931.54, 11029.96, 10906.27, 11100.52, 11099.79, 11335.46, 11801.17, 11071.36, 11219.68, 11191.99, 11744.91, 11762.47, 11594.36, 11761.02, 11681.69, 11892.9, 11392.09, 11564.34, 11779.77, 11760.55, 11852.4, 11910.99, 12281.15, 11945.1, 11754.38]\n",
    "\n",
    "df = pd.DataFrame(dict(x=x))\n",
    "x_filtered = df[[\"x\"]].apply(savgol_filter,  window_length=31, polyorder=2)\n",
    "\n",
    "plt.ion()\n",
    "plt.plot(x)\n",
    "plt.plot(x_filtered)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchkpop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b284e58fd91e2b911d82a9377f2de4f2e1330c2d7d1dea6eddeeded52077f0ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
