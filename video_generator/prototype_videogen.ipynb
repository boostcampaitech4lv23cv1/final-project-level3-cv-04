{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "from glob import glob\n",
    "import cv2\n",
    "import csv\n",
    "import pandas as pd\n",
    "import natsort\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "import json\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter   \n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## file_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/final-project-level3-cv-04/result/vvSGDIGPiPk/100/csv/pred.pickle', mode='rb') as f:\n",
    "    pred = pickle.load(f)\n",
    "\n",
    "with open('/opt/ml/final-project-level3-cv-04/result/vvSGDIGPiPk/100/csv/df1_face.pickle', mode='rb') as f:\n",
    "    df1 = pickle.load(f)\n",
    "\n",
    "with open('/opt/ml/final-project-level3-cv-04/result/vvSGDIGPiPk/100/vvSGDIGPiPk.json', mode='r') as f:\n",
    "    meta_info = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### clansing\n",
    "def clansing(df:pd.DataFrame, pred:dict) -> pd.DataFrame:\n",
    "    # drop useless column\n",
    "    df.drop(['det_body_xmin', \n",
    "             'det_body_ymin', \n",
    "             'det_body_xmax',\n",
    "             'det_body_ymax',\n",
    "             'det_conf',\n",
    "             'track_body_xmin',\n",
    "             'track_body_ymin',\n",
    "             'track_body_xmax',\n",
    "             'track_body_ymax',\n",
    "             'track_conf',\n",
    "             'num_overlap_bboxes',\n",
    "             'intercept_iou',\n",
    "             'isfront',\n",
    "             'face_bbox',\n",
    "             'face_embedding',\n",
    "             'face_confidence'], axis=1, inplace=True)\n",
    "    # track_id type change\n",
    "    df['track_id'] = df['track_id'].astype('int32')\n",
    "\n",
    "    # assign name\n",
    "    for k,v in pred.items():\n",
    "        df.loc[df['track_id']==k,'name'] = v\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "#### get face order\n",
    "def get_order(element, lst):\n",
    "    try:\n",
    "        return lst.index(element)\n",
    "    except ValueError:\n",
    "        return -1\n",
    "\n",
    "\n",
    "#### for key point assign\n",
    "def get_keypoint(element, idx):\n",
    "    if idx != -1:\n",
    "        left_eye_point = element[idx][0]\n",
    "        right_eye_point = element[idx][1]\n",
    "        center_point = [int((x + y)/2) for x, y in zip(left_eye_point, right_eye_point)]\n",
    "        return center_point\n",
    "    else: # if un detected keypoints return [-1,-1]\n",
    "        return [-1, -1]\n",
    "\n",
    "\n",
    "#### add bbox column\n",
    "def keypoint_center_bounding_box(coord, crop_width, crop_height):\n",
    "    x, y = coord\n",
    "    if x==-1 or y==-1: # if undetected keypoints [-1,-1]\n",
    "        return [-1,-1,-1,-1]\n",
    "    x_min = x - crop_width / 2\n",
    "    y_min = y - crop_height / 2\n",
    "    x_max = x + crop_width / 2\n",
    "    y_max = y + crop_height / 2\n",
    "    coordinate = [int(i) for i in [x_min, y_min, x_max, y_max]] # int coordinate\n",
    "    return coordinate\n",
    "\n",
    "\n",
    "#### add shift bbox column\n",
    "def shift_bounding_box(bbox, shift_ratio, meta_info):\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "    if x_min == -1 or y_min == -1 or x_max == -1 or y_max == -1:\n",
    "        return [0,0,meta_info['width'],meta_info['height']]\n",
    "    height = y_max - y_min\n",
    "    y_min += height * shift_ratio\n",
    "    y_max += height * shift_ratio\n",
    "    coordinate = [int(i) for i in [x_min, y_min, x_max, y_max]]\n",
    "    return coordinate\n",
    "\n",
    "\n",
    "#### add missing rows\n",
    "def add_missing_files(df, all_files, name, meta_info):\n",
    "    missing_files = set(all_files) - set(df['filename'])\n",
    "    if missing_files:\n",
    "        missing_df = pd.DataFrame({\n",
    "                                    'frame':[int(filename.split('.')[0]) for filename in list(missing_files)],\n",
    "                                    'filename': list(missing_files), \n",
    "                                    'name': [name for i in list(missing_files)],\n",
    "                                    'shift_bbox': [[0,0,meta_info['width'],meta_info['height']] for i in list(missing_files)],\n",
    "                                    })\n",
    "        df = df.append(missing_df, ignore_index=True)\n",
    "    \n",
    "    df = df.sort_values(by='frame' ,ascending=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def replace_values(row, target_col, width, height):\n",
    "    xmin, ymin, xmax, ymax = row[target_col]\n",
    "    if xmin == 0 and ymin == 0 and xmax >= width:\n",
    "        row[target_col] = [0, 0, width, ymax]\n",
    "    if xmin == 0 and ymin == 0 and ymax >= height:\n",
    "        row[target_col] = [0, 0, xmax, height]\n",
    "    return row\n",
    "\n",
    "\n",
    "def update_overange_bounding_box(df, target_col,width, height):\n",
    "    df = df.apply(lambda row: replace_values(row, target_col, width, height), axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "#### Define a function to collect the values of columns A, B, C, and D as a list\n",
    "def collect_values(row):\n",
    "    return [row['xmin'], row['ymin'], row['xmax'], row['ymax']]\n",
    "\n",
    "\n",
    "#### tagging untrack frame\n",
    "def tagging_untrack_frame(row, meta_info):\n",
    "    if row == [0, 0, meta_info['width'], meta_info['height']]:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "# for plotting time series\n",
    "def plot_time_series(df, target_col, prefix, filename, col=2):\n",
    "    colname = \"xmax\" if col==2 else \"ymax\"\n",
    "    # Extract xmax from each row of A and store it as a new column xmax\n",
    "    temp = pd.DataFrame()\n",
    "    temp['max'] = df[target_col].apply(lambda x: x[col])\n",
    "    # Plot xmax as a time series\n",
    "    plt.plot(temp['max'])\n",
    "    plt.xlabel(colname)\n",
    "    plt.ylabel('coorinate')\n",
    "    plt.title('Time Series Plot')\n",
    "    # Save the plot\n",
    "    filename = f'{colname}_plot_{prefix}_{filename}.png'\n",
    "    filepath = os.path.join(os.getcwd(), filename)\n",
    "    plt.savefig(filepath)\n",
    "    return filepath\n",
    "\n",
    "\n",
    "# savitzky_golay smoothing\n",
    "def savitzky_golay(df, target_column, output_column):\n",
    "    # split coordinates\n",
    "    df['xmin'] = [coordinate[0] for coordinate in df[target_column]]\n",
    "    df['ymin'] = [coordinate[1] for coordinate in df[target_column]]\n",
    "    df['xmax'] = [coordinate[2] for coordinate in df[target_column]]\n",
    "    df['ymax'] = [coordinate[3] for coordinate in df[target_column]]\n",
    "    \n",
    "    df['xmin'] = df[['xmin']].apply(savgol_filter,  window_length=45, polyorder=2)\n",
    "    df['ymin'] = df[['ymin']].apply(savgol_filter,  window_length=45, polyorder=2)\n",
    "    df['xmax'] = df[['xmax']].apply(savgol_filter,  window_length=45, polyorder=2)\n",
    "    df['ymax'] = df[['ymax']].apply(savgol_filter,  window_length=45, polyorder=2)\n",
    "\n",
    "    df['xmin'] = df['xmin'].astype('int')\n",
    "    df['ymin'] = df['ymin'].astype('int')\n",
    "    df['xmax'] = df['xmax'].astype('int')\n",
    "    df['ymax'] = df['ymax'].astype('int')\n",
    "\n",
    "    df[output_column] = df.apply(collect_values, axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def moving_average(df, window_size, target_column,  output_column):\n",
    "    # split coordinates\n",
    "    df['xmin'] = [coordinate[0] for coordinate in df[target_column]]\n",
    "    df['ymin'] = [coordinate[1] for coordinate in df[target_column]]\n",
    "    df['xmax'] = [coordinate[2] for coordinate in df[target_column]]\n",
    "    df['ymax'] = [coordinate[3] for coordinate in df[target_column]]\n",
    "\n",
    "    def smoothing(row, window):\n",
    "        window = row.rolling(window)\n",
    "        mean = window.mean()\n",
    "        result = np.where(np.isnan(mean), row, mean)\n",
    "        return result\n",
    "    \n",
    "    df['xmin'] = df[['xmin']].apply(smoothing, args=(window_size,))\n",
    "    df['ymin'] = df[['ymin']].apply(smoothing, args=(window_size,))\n",
    "    df['xmax'] = df[['xmax']].apply(smoothing, args=(window_size,))\n",
    "    df['ymax'] = df[['ymax']].apply(smoothing, args=(window_size,))\n",
    "\n",
    "    df['xmin'] = df['xmin'].astype('int')\n",
    "    df['ymin'] = df['ymin'].astype('int')\n",
    "    df['xmax'] = df['xmax'].astype('int')\n",
    "    df['ymax'] = df['ymax'].astype('int')\n",
    "\n",
    "    df[output_column] = df.apply(collect_values, axis=1)\n",
    "\n",
    "    df = df.drop(['xmin', 'ymin', 'xmax', 'ymax'], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def moving_median(df, window_size, target_column,  output_column):\n",
    "    # split coordinates\n",
    "    df['xmin'] = [coordinate[0] for coordinate in df[target_column]]\n",
    "    df['ymin'] = [coordinate[1] for coordinate in df[target_column]]\n",
    "    df['xmax'] = [coordinate[2] for coordinate in df[target_column]]\n",
    "    df['ymax'] = [coordinate[3] for coordinate in df[target_column]]\n",
    "\n",
    "    def smoothing(row, window):\n",
    "        window = row.rolling(window)\n",
    "        mean = window.median()\n",
    "        result = np.where(np.isnan(mean), row, mean)\n",
    "        return result\n",
    "    \n",
    "    df['xmin'] = df[['xmin']].apply(smoothing, args=(window_size,))\n",
    "    df['ymin'] = df[['ymin']].apply(smoothing, args=(window_size,))\n",
    "    df['xmax'] = df[['xmax']].apply(smoothing, args=(window_size,))\n",
    "    df['ymax'] = df[['ymax']].apply(smoothing, args=(window_size,))\n",
    "\n",
    "    df['xmin'] = df['xmin'].astype('int')\n",
    "    df['ymin'] = df['ymin'].astype('int')\n",
    "    df['xmax'] = df['xmax'].astype('int')\n",
    "    df['ymax'] = df['ymax'].astype('int')\n",
    "\n",
    "    df[output_column] = df.apply(collect_values, axis=1)\n",
    "\n",
    "    df = df.drop(['xmin', 'ymin', 'xmax', 'ymax'], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def trim(df):\n",
    "    # drop useless column\n",
    "    df.drop(['face_keypoint', \n",
    "             'face_pred', \n",
    "             'key_point_order',\n",
    "             'center_point',\n",
    "            ], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# top, bottom, left, right\n",
    "def img_padding(img, xmin, ymin, xmax, ymax, w, h):\n",
    "    if xmax>w:\n",
    "        img = cv2.copyMakeBorder(img, 0, 0, 0, xmax-w, cv2.BORDER_CONSTANT)\n",
    "    if xmin<0: \n",
    "        img = cv2.copyMakeBorder(img, 0, 0,-xmin, 0, cv2.BORDER_CONSTANT)\n",
    "        xmax = xmax - xmin \n",
    "        xmin = 0\n",
    "    if ymax>h:\n",
    "        img = cv2.copyMakeBorder(img, 0, ymax-h, 0, 0, cv2.BORDER_CONSTANT)\n",
    "    if ymin<0:\n",
    "        img = cv2.copyMakeBorder(img, -ymin, 0, 0, 0, cv2.BORDER_CONSTANT)\n",
    "        py = ymax - ymin\n",
    "        ymin = 0\n",
    "    return img, xmin, ymin, xmax, ymax\n",
    "\n",
    "\n",
    "def short_untrack_bbox_update(df, target_col_name, new_col_name,keep_threshold, meta_info):\n",
    "    df[new_col_name] = [None] * len(df)\n",
    "    df.at[0, new_col_name] = df.at[0, target_col_name]\n",
    "    cnt=0\n",
    "    last_state=None\n",
    "    df['is_track_update'] = [False]*len(df)\n",
    "    for i in range(1, len(df)):\n",
    "        # if untrack case\n",
    "        if df.at[i, target_col_name] == [0,0,meta_info['width'],meta_info['height']] and df.at[i, 'is_track'] == False:\n",
    "            # increase cnt\n",
    "            cnt+=1\n",
    "            if i > 0 and i < len(df) - 1:\n",
    "                # move avg\n",
    "                '''\n",
    "                # calculate the average of the previous and next values for each component of shift_bbox\n",
    "                xmin = int((df.at[i-1, 'shift_bbox'][0] + df.at[i+1, 'shift_bbox'][0]) / 2)\n",
    "                ymin = int((df.at[i-1, 'shift_bbox'][1] + df.at[i+1, 'shift_bbox'][1]) / 2)\n",
    "                xmax = int((df.at[i-1, 'shift_bbox'][2] + df.at[i+1, 'shift_bbox'][2]) / 2)\n",
    "                ymax = int((df.at[i-1, 'shift_bbox'][3] + df.at[i+1, 'shift_bbox'][3]) / 2)\n",
    "                # update the values of shift_bbox in the current row\n",
    "                df.at[i, 'increase_decrease_bbox'] = [xmin, ymin, xmax, ymax]\n",
    "                # update state\n",
    "                '''\n",
    "                # keep value\n",
    "                df.at[i, new_col_name] = [0,0,meta_info['width'],meta_info['height']]\n",
    "            elif i == 0:\n",
    "                # if the current row is the first & undetect row, take the value of the next row\n",
    "                df.at[i, new_col_name] = df.at[i+1, target_col_name]\n",
    "            else:\n",
    "                # if the current row is the last & undetect row, take the value of the previous row\n",
    "                df.at[i, new_col_name] = df.at[i-1, target_col_name]\n",
    "        # if tracked appeared\n",
    "        else:\n",
    "            # short_lange untrack case, fill last_state\n",
    "            if 0<cnt<keep_threshold:\n",
    "                for j in range(cnt):\n",
    "                    target_idx = i-(j+1)\n",
    "                    df.at[target_idx, new_col_name] = last_state\n",
    "                    df.at[target_idx, 'is_track_update'] = True # if short time state update\n",
    "                \n",
    "            # long_lange untrack case, don't care\n",
    "            elif cnt>=keep_threshold:\n",
    "                pass\n",
    "            \n",
    "            cnt=0\n",
    "            # untracked case just keep [0, 0, width, height] value\n",
    "            df.at[i, new_col_name] = df.at[i, target_col_name]\n",
    "            last_state=df.at[i, target_col_name]\n",
    "        \n",
    "    df['need_padding'] = df['is_track'] | df['is_track_update']\n",
    "    return df\n",
    "\n",
    "\n",
    "def crop_resize_save_img(df, img_dir_path, save_dir, name, meta_info, target_col, window_height, window_width, mode, fullscreen):\n",
    "    mini_df = df[['filename', target_col, 'need_padding']]\n",
    "    cnt=0\n",
    "    width = meta_info['width']\n",
    "    height = meta_info['height']\n",
    "    padded_box = []\n",
    "    # make dir\n",
    "    dir_path = osp.join(save_dir, name)\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    print(f\"start cropping {len(df)} images.\")\n",
    "    for order, (index, row) in tqdm(enumerate(mini_df.iterrows())):\n",
    "        # load\n",
    "        img = cv2.imread(osp.join(img_dir_path, row['filename']))\n",
    "        \n",
    "        # get bbox coordinate\n",
    "        xmin, ymin, xmax, ymax = row[target_col][0], row[target_col][1], row[target_col][2], row[target_col][3]\n",
    "\n",
    "        if row['need_padding']: # tracked\n",
    "            # get center-point\n",
    "            center_y, center_x = (ymin+ymax)//2, (xmin+xmax)//2\n",
    "            # get new xmin, ymin, xmax, ymax\n",
    "            xmin, ymin, xmax, ymax = center_x-window_width//2, center_y-window_height//2, center_x+window_width//2, center_y+window_height//2\n",
    "            # if over range, padding around\n",
    "            if xmax>width or xmin<0 or ymax>height or ymin<0:\n",
    "                img, xmin, ymin, xmax, ymax = img_padding(img, xmin, ymin, xmax, ymax, width, height)\n",
    "            # crop\n",
    "            img = img[ymin:ymax, xmin:xmax]\n",
    "        \n",
    "        else: # untracked\n",
    "            if fullscreen==True: # mode == 'normal' \n",
    "                img = cv2.resize(img, dsize=(meta_info['width'], meta_info['height']), interpolation=cv2.INTER_CUBIC)\n",
    "                xmin, ymin, xmax, ymax = 0, 0, window_width, window_height\n",
    "            else: # fullscreen==False:\n",
    "                center_y, center_x = (ymin+ymax)//2, (xmin+xmax)//2\n",
    "                # get new xmin, ymin, xmax, ymax\n",
    "                xmin, ymin, xmax, ymax = center_x-window_width//2, center_y-window_height//2, center_x+window_width//2, center_y+window_height//2\n",
    "                img = img[ymin:ymax, xmin:xmax]\n",
    "        \n",
    "        # append\n",
    "        padded_box.append([xmin, ymin, xmax, ymax])\n",
    "        # if unmatching window img print size\n",
    "        if img.shape[0] != window_height and img.shape[1] != window_width:\n",
    "            # print(img.shape[0], window_height, img.shape[1], window_width)\n",
    "            pass\n",
    "        # write img\n",
    "        cv2.imwrite(osp.join(dir_path, row['filename']), img)\n",
    "    df['cropped_box'] = padded_box\n",
    "    return df, dir_path\n",
    "\n",
    "\n",
    "def enlarge_with_padding(img, crop_width, crop_height, window_width, window_height, padding_tag, path):\n",
    "    if padding_tag == True:\n",
    "        padded_img = np.zeros((window_height, window_width, 3), dtype=np.uint8)\n",
    "        x_offset = int((window_width - crop_width) / 2)\n",
    "        y_offset = int((window_height - crop_height) / 2)\n",
    "        try:\n",
    "           padded_img[y_offset:y_offset+crop_height, x_offset:x_offset+crop_width, :] = img\n",
    "        except:\n",
    "            print(f\"error occur in enlarge_with_padding, file: {path}\")\n",
    "            print(\"input img size:\", img.shape)\n",
    "            print(f\"window size: ({window_height}, {window_width})\" )\n",
    "            print(\"so just resize\")\n",
    "            padded_img = cv2.resize(img, (window_width, window_height), interpolation=cv2.INTER_CUBIC)\n",
    "    else:\n",
    "        padded_img = cv2.resize(img, (window_width, window_height), interpolation=cv2.INTER_CUBIC)\n",
    "    return padded_img\n",
    "\n",
    "\n",
    "def make_video(dir_path, df, meta_info, save_dir, window_height, window_width, name):\n",
    "    files = os.listdir(dir_path)\n",
    "    padding_tags = df['need_padding'].to_list()\n",
    "    img_list = natsort.natsorted(files)\n",
    "    img_paths = [osp.join(dir_path, i) for i in img_list]\n",
    "    video_path = osp.join(save_dir, f'{name}_output.mp4')\n",
    "    out = cv2.VideoWriter(video_path,\n",
    "                          cv2.VideoWriter_fourcc(*'mp4v'), \n",
    "                          meta_info['fps'], \n",
    "                          (window_width, window_height))\n",
    "    img = cv2.imread(img_paths[0])\n",
    "    crop_h,crop_w,c = img.shape\n",
    "\n",
    "    tag = 'normal'\n",
    "    if window_height == crop_h and window_width == crop_w:\n",
    "        tag = 'normal'\n",
    "    elif window_height == crop_h and window_width != crop_w:\n",
    "        tag = 'vertical'\n",
    "    elif window_height != crop_h and window_width == crop_w:\n",
    "        tag = 'horizontal'\n",
    "    else:\n",
    "        raise ValueError(\"view type error\")\n",
    "\n",
    "    print(f\"{name}'s video recoding...\")\n",
    "    for path, padding_tag in tqdm(zip(img_paths, padding_tags)):\n",
    "        img = cv2.imread(path)\n",
    "        # enlarge_with_padding(img, crop_width, crop_height, window_width, window_height)\n",
    "        if tag == 'vertical' or tag=='horizontal':\n",
    "            # def enlarge_with_padding(img, crop_width, crop_height, window_width, window_height, padding_tag):\n",
    "            img = enlarge_with_padding(img, crop_w, crop_h, window_width, window_height, padding_tag, path)\n",
    "        # if normal don't need post processing\n",
    "        out.write(img)\n",
    "    out.release()\n",
    "    h,w,c = img.shape\n",
    "    return video_path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def video_gen(df:pd.DataFrame, meta_info:dict, member:str, pred:dict,  save_dir:str,\n",
    "              window_ratio:float, aespect_ratio:float, shift_bb:float, fullscreen=True):\n",
    "    view_type = None\n",
    "    # calc window size\n",
    "    window_height = int(meta_info['height']*window_ratio)\n",
    "    window_width = int(meta_info['width']*window_ratio)\n",
    "    \n",
    "\n",
    "    # calc crop_size and assign mode\n",
    "    if aespect_ratio >= 1:\n",
    "        print('horizontal video mode')\n",
    "        mode = 'horizontal'\n",
    "        crop_width = window_width # width is Criteria\n",
    "        crop_height = int(crop_width * 1/aespect_ratio)\n",
    "        if fullscreen==False:\n",
    "            ValueError(f\"{mode} must need full screen\")\n",
    "    elif aespect_ratio==0:\n",
    "        print('normal video mode')\n",
    "        mode = 'normal'\n",
    "        crop_height = window_height # hold the original video asepect\n",
    "        crop_width = window_width\n",
    "    else:\n",
    "        print('vertical video mode')\n",
    "        mode = 'vertical'\n",
    "        crop_height = window_height # height is Criteria\n",
    "        crop_width = int(crop_height*aespect_ratio)\n",
    "        if fullscreen==False:\n",
    "            ValueError(f\"{mode} must need full screen\")\n",
    "\n",
    "    print(f'window size: hegiht: {window_height}, width: {window_width}')\n",
    "    print(f'video mode: hegiht: {mode}')\n",
    "    print(f'show full screen: {fullscreen}')\n",
    "    # 1. clansing df\n",
    "    df = clansing(df, pred)\n",
    "    \n",
    "    # 2. assign key_point order\n",
    "    df['key_point_order'] = df.apply(lambda x: get_order(x['name'], x['face_pred']), axis=1)\n",
    "\n",
    "    # 3. get center point(int type)\n",
    "    df['center_point'] = df.apply(lambda x: get_keypoint(x['face_keypoint'], x['key_point_order']), axis=1)\n",
    "\n",
    "    # 4. get center_bbox(bbox center is key_point)\n",
    "    df['center_bbox'] = df['center_point'].apply(lambda x: keypoint_center_bounding_box(x, crop_height, crop_width))\n",
    "\n",
    "    # 5. shifting bbox, if undetected keypoints or unmatching preds bbox is [0, 0, meta_info['width'], meta_info['height']]\n",
    "    df['shift_bbox'] = df['center_bbox'].apply(lambda x: shift_bounding_box(x, shift_bb, meta_info))\n",
    "\n",
    "    # 6. extract selected member\n",
    "    df = df[df['name'] == member]\n",
    "    # print(f'after member select {len(df)} rows left.') # for debugging\n",
    "\n",
    "    # 7. get all captures img filenames\n",
    "    img_dir_path = meta_info['image_root'].replace('.','..') # change for current path\n",
    "    img_files = os.listdir(img_dir_path)\n",
    "\n",
    "    # 8. add missing rows\n",
    "    df = add_missing_files(df, img_files, member, meta_info)\n",
    "    img_path = plot_time_series(df, 'shift_bbox', \"0\", 'add_missing_files', col=2) # debug\n",
    "    # print(f'img_path: {img_path}')\n",
    "\n",
    "    # 9. tagging untracked frame\n",
    "    df['is_track'] = df['shift_bbox'].apply(lambda x: tagging_untrack_frame(x, meta_info))\n",
    "    \n",
    "    # 10. trim, drop useless column\n",
    "    df = trim(df)\n",
    "\n",
    "    # 11. moving avg untrack row, ignore threshold\n",
    "    df = short_untrack_bbox_update(df, 'shift_bbox', 'ignore_short_untrack',meta_info['fps']*5, meta_info) # df add column increase_decrease_bbox\n",
    "    img_path = plot_time_series(df, 'ignore_short_untrack', 1, 'ignore_short_untrack', col=2) # debug\n",
    "    # print(f'img_path: {img_path}') # debug\n",
    "    \n",
    "    # 12. smoothing ⭐\n",
    "    df = moving_median(df, meta_info['fps']*1, 'ignore_short_untrack', 'median_bbox')\n",
    "    df = moving_average(df, int(meta_info['fps']*.5), 'median_bbox', 'smoothed_bbox')\n",
    "    # df = savitzky_golay(df, 'median_bbox', 'smoothed_bbox') # df add column smoothed_bbox\n",
    "    img_path = plot_time_series(df, 'smoothed_bbox', 2, 'moving_median_avg', col=2) # debug\n",
    "    print(f'img_path: {img_path}') # debug\n",
    "    \n",
    "    #\n",
    "    df = df.drop_duplicates(subset='filename', keep='first')\n",
    "    # img_path = plot_time_series(df, 'smoothed_bbox', 3, 'drop_duplicates', col=2) # debug\n",
    "    # print(f'img_path: {img_path}') # debug\n",
    "    \n",
    "    \n",
    "    # 13. clip img for over bbox, if long untracked frame made by resume\n",
    "    df, crop_img_path = crop_resize_save_img(df, \n",
    "                                             img_dir_path, \n",
    "                                             save_dir, \n",
    "                                             member, \n",
    "                                             meta_info, \n",
    "                                             'smoothed_bbox', \n",
    "                                             crop_height, \n",
    "                                             crop_width, \n",
    "                                             mode,\n",
    "                                             fullscreen)\n",
    "\n",
    "    \n",
    "    # 14. making video\n",
    "    video_path = make_video(crop_img_path, df, meta_info, save_dir, window_height, window_width, member)\n",
    "    \n",
    "    # 15. delete crop imgs\n",
    "    shutil.rmtree(crop_img_path)\n",
    "    \n",
    "    return video_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## video make"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### aespa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # normal\n",
    "# video_gen(df1,  meta_info, 'aespa_winter', pred, './', \n",
    "#           window_ratio=0.5, aespect_ratio=0., shift_bb=0.2, fullscreen=True) # asepect_ratio = width/height\n",
    "# os.rename(\"./aespa_winter_output.mp4\", \"./aespa_winter_normal_w50as0shft20_fullscrn.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # normal\n",
    "# video_gen(df1,  meta_info, 'aespa_winter', pred, './', \n",
    "#           window_ratio=0.5, aespect_ratio=0., shift_bb=0.2, fullscreen=False) # asepect_ratio = width/height\n",
    "# os.rename(\"./aespa_winter_output.mp4\", \"./aespa_winter_normal_w50as0shft20_fullscrn_false.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # vertical\n",
    "# video_gen(df1,  meta_info, 'aespa_winter', pred, './', \n",
    "#           window_ratio=0.5, aespect_ratio=0.5, shift_bb=0.8, fullscreen=True) # asepect_ratio = width/height\n",
    "# os.rename(\"./aespa_winter_output.mp4\", \"./aespa_winter_vertical_median.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # vertical\n",
    "# video_gen(df1,  meta_info, 'aespa_winter', pred, './', \n",
    "#           window_ratio=0.5, aespect_ratio=0.5, shift_bb=0.8, fullscreen=True) # asepect_ratio = width/height\n",
    "# os.rename(\"./aespa_winter_output.mp4\", \"./aespa_winter_vertical_median_average.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # horizontal\n",
    "# video_gen(df1,  meta_info, 'aespa_winter', pred, './', \n",
    "#           window_ratio=0.5, aespect_ratio=2.5, shift_bb=0.1, fullscreen=True) # asepect_ratio = width/height\n",
    "# os.rename(\"./aespa_winter_output.mp4\", \"./aespa_winter_horizontal_w50as250shft10.mp4\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### newjeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # normal\n",
    "# video_gen(df1,  meta_info, 'newjeans_minji', pred, './', \n",
    "#           window_ratio=0.4, aespect_ratio=0., shift_bb=0.1).to_csv('newjeans_smooth_normal_w40as0shft10_v3.csv') # asepect_ratio = width/height\n",
    "# os.rename(\"./newjeans_minji_output.mp4\", \"./newjeans_smooth_normal_w40as0shft10_v3.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # vertical\n",
    "# video_gen(df1,  meta_info, 'newjeans_minji', pred, './', \n",
    "#           window_ratio=0.5, aespect_ratio=0.7, shift_bb=0.4, fullscreen=False).to_csv('newjeans_smooth_vertical_w50as07shft40.csv') # asepect_ratio = width/height\n",
    "# os.rename(\"./newjeans_minji_output.mp4\", \"./newjeans_smooth_vertical_w50as07shft40_v3.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # horizontal\n",
    "# video_gen(df1,  meta_info, 'newjeans_minji', pred, './', \n",
    "#           window_ratio=0.4, aespect_ratio=2, shift_bb=0.01).to_csv('newjeans_smooth_horizontal_w40as20shft1.csv') # asepect_ratio = width/height\n",
    "# os.rename(\"./newjeans_minji_output.mp4\", \"./newjeans_smooth_horizontal_w40as20shft1_v3.mp4\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # normal\n",
    "# video_gen(df1,  meta_info, 'newjeans_minji', pred, './', \n",
    "#           window_ratio=0.4, aespect_ratio=0., shift_bb=0.1, fullscreen=False).to_csv('newjeans_test_window30.csv') # asepect_ratio = width/height\n",
    "# os.rename(\"./newjeans_minji_output.mp4\", \"./newjeans_test_window60_NO_FSCR.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # normal\n",
    "# video_gen(df1,  meta_info, 'newjeans_minji', pred, './', \n",
    "#           window_ratio=0.4, aespect_ratio=0., shift_bb=0.1, fullscreen=True).to_csv('newjeans_test_window60.csv') # asepect_ratio = width/height\n",
    "# os.rename(\"./newjeans_minji_output.mp4\", \"./newjeans_test_window60_FSCR.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # vertical\n",
    "# video_gen(df1,  meta_info, 'newjeans_minji', pred, './', \n",
    "#           window_ratio=0.5, aespect_ratio=0.7, shift_bb=0.4, fullscreen=True).to_csv('newjeans_smooth_vertical_w50as07shft40.csv') # asepect_ratio = width/height\n",
    "# os.rename(\"./newjeans_minji_output.mp4\", \"./newjeans_smooth_vertical_.mp4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchkpop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b284e58fd91e2b911d82a9377f2de4f2e1330c2d7d1dea6eddeeded52077f0ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
